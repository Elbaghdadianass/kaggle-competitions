{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # DeepTweets Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team name : PGX- DS-T3256\n",
    "#### User-name : ORCL-DS-APP3791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries used for dataset preparation, feature engineering, model training \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas, numpy, textblob, string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from textblob import Word\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the train and test data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step i did some basic pre-processing such as removing punctuation, stopwords, digits, Lemmatization and i also observed that the dataset contains a lot of hyperlinks so i did removed them at last and it gived a pretty good improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "# Lower case\n",
    "train['TweetText'] = train['TweetText'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test['TweetText'] = test['TweetText'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "# Removing punctuation\n",
    "train['TweetText'] = train['TweetText'].str.replace('[^\\w\\s]','')\n",
    "test['TweetText'] = test['TweetText'].str.replace('[^\\w\\s]','')\n",
    "# removing stopwords\n",
    "train['TweetText'] = train['TweetText'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test['TweetText'] = test['TweetText'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# Lemmatization\n",
    "train['TweetText'] = train['TweetText'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "test['TweetText'] = test['TweetText'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "# removing digits\n",
    "train['TweetText'] = train['TweetText'].apply(lambda x: ' '.join([x for x in x.split() if not x.isdigit()]))\n",
    "test['TweetText'] = test['TweetText'].apply(lambda x: ' '.join([x for x in x.split() if not x.isdigit()]))\n",
    "# removing links\n",
    "for i in range(len(train['TweetText'])):\n",
    "    train['TweetText'][i] = re.sub(r\"http\\S+\", '', train['TweetText'][i])\n",
    "for i in range(len(test['TweetText'])):\n",
    "    test['TweetText'][i] = re.sub(r\"http\\S+\", '', test['TweetText'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation set\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train['TweetText'], train['Label'])\n",
    "# and finaly label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step i transformed raw text data into feature vectors such as the count Vectors and the TF-IDF vectors for a word level and also n-grams level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train['TweetText'])\n",
    "count_vect.fit(test['TweetText'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)\n",
    "xtest_count =  count_vect.transform(test['TweetText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a word level tf-idf vector\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(train['TweetText'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "xtest_tfidf =  tfidf_vect.transform(test['TweetText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ngram level tf-idf vector\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=5000)\n",
    "tfidf_vect_ngram.fit(train['TweetText'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test['TweetText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this step i trained several models on the three vectors that i created in the step before and i displayed the accuracy of each one for a comparaison between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is simple function to train a model and display the accuracy\n",
    "def model_training(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracyc = model_training(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"NB, Count Vectors: \", accuracyc)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = model_training(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = model_training(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = model_training(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = model_training(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = model_training(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"LR, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy = model_training(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = model_training(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = model_training(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"RF, WordLevel n-grams TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the final submission i used the Naive Bayes on Word Level TF-IDF model as it performed the best on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on word level\n",
    "model_nv = naive_bayes.MultinomialNB().fit(xtrain_tfidf, train_y)\n",
    "predictions = model_nv.predict(xtest_tfidf)\n",
    "pred = ['Politics' if i == 0 else 'Sports' for i in predictions]\n",
    "pd.DataFrame({'TweetId': test['TweetId'], 'Label': pred}).to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also tried combining different models, i used a basic ensemble technique called max-voting on different models but it didn't improve the final results. Here is the code below for this model (i used the VotingClassifier from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nv = naive_bayes.MultinomialNB()\n",
    "model_rf = ensemble.RandomForestClassifier()\n",
    "model_ln = linear_model.LogisticRegression()\n",
    "model_svm = linear_model.SGDClassifier()\n",
    "\n",
    "model_vote = VotingClassifier(estimators=[('nv', model_nv), ('ln', model_ln),('rf', model_rf), ('svm',model_svm)], voting='hard')\n",
    "model_vote.fit(xtrain_tfidf,train_y)\n",
    "\n",
    "predictions = model_vote.predict(xtest_tfidf)\n",
    "pred = ['Politics' if i == 0 else 'Sports' for i in predictions]\n",
    "pd.DataFrame({'TweetId': test['TweetId'], 'Label': pred}).to_csv('results_stacked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect Data : We can collect more data from Twitter using the Twitter API and label them for the training part because the training data for the competition is very poor but still balanced. In the collect we also need to keep the balance for a robust model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
